{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5692,"status":"ok","timestamp":1716977811057,"user":{"displayName":"劉睿恩","userId":"02664673059107579658"},"user_tz":-480},"id":"zSV8SFqSrZ1g"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":2022,"status":"error","timestamp":1716977874427,"user":{"displayName":"劉睿恩","userId":"02664673059107579658"},"user_tz":-480},"id":"cG9qwux-rkYy","outputId":"c510a39b-15ed-4a97-8769-abe6a302c5f8"},"outputs":[],"source":["# 讀取所有圖片的檔案名稱\n","img_dir = './pokemon4'  # pokemon 資料夾路徑\n","img_names = os.listdir(img_dir)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716969952767,"user":{"displayName":"劉睿恩","userId":"00959352732132293814"},"user_tz":-480},"id":"6vEWNe7Dr7wi","outputId":"3317753f-c02d-44c9-abde-887b8caab17f"},"outputs":[{"name":"stdout","output_type":"stream","text":["15100\n"]}],"source":["import tensorflow as tf\n","print(len(img_names)) #img_names is list\n","#print(img_names[1])\n","#print(img_names[1][0:4])\n","label = [] #one-hot編碼\n","#for num_img in range(len(img_names)) :\n","#  if(img_names[num_img][0]!='0') :\n","#    label.append(str((int(img_names[num_img][0:4])-1)))\n","#  elif(img_names[num_img][1]!='0') :\n","#    label.append(str((int(img_names[num_img][1:4])-1)))\n","#  elif(img_names[num_img][2]!='0') :\n","#    label.append(str((int(img_names[num_img][2:4])-1)))\n","#  elif(img_names[num_img][3]!='0') :\n","#    label.append(str((int(img_names[num_img][3:4])-1)))\n","#  else :\n","#    label.append(str((int(img_names[num_img][4])-1)))\n","for num_img in range(len(img_names)) :\n","    if(img_names[num_img][1]=='_') :\n","        label.append(str((int(img_names[num_img][0])-1)))\n","    else :\n","        label.append(str((int(img_names[num_img][0:2])-1)))\n","labels = tf.keras.utils.to_categorical(label, num_classes=27)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"K36qgKnUwbEC"},"outputs":[],"source":["import os\n","from sklearn.model_selection import train_test_split\n","\n","# 定義讀取和處理圖片的函數\n","def load_and_process_image(filepath):\n","    image = tf.io.read_file(filepath)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(image, [256, 256])\n","    image = tf.cast(image, tf.float32) / 255.0\n","    return image\n","\n","# 獲取所有圖片文件的路徑\n","filepaths = [os.path.join(img_dir, fname) for fname in os.listdir(img_dir) if fname.endswith('.png')]\n","\n","# 使用 train_test_split 分割數據集\n","filepaths_train, filepaths_test,  labels_train, labels_test  = train_test_split(filepaths, labels, test_size=0.2, random_state=1)\n","filepaths_train, filepaths_valid, labels_train,  labels_valid = train_test_split(filepaths_train, labels_train, test_size=0.2, random_state=1)\n","# 將訓練和測試數據轉換為 tf.data.Dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices((filepaths_train, labels_train))\n","train_dataset = train_dataset.map(lambda filepath, label: (load_and_process_image(filepath), label))\n","\n","valid_dataset = tf.data.Dataset.from_tensor_slices((filepaths_valid, labels_valid))\n","valid_dataset = valid_dataset.map(lambda filepath, label: (load_and_process_image(filepath), label))\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((filepaths_test, labels_test))\n","test_dataset = test_dataset.map(lambda filepath, label: (load_and_process_image(filepath), label))\n","\n","# 設定批次大小和緩存\n","batch_size  = 32\n","train_dataset = train_dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","valid_dataset = valid_dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tqjnYEU35065"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n","                                                                 \n"," batch_normalization (Batch  (None, 256, 256, 64)      256       \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 128, 128, 64)      0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 128, 128, 128)     73856     \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 128, 128, 128)     512       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 128, 128, 128)     147584    \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 128, 128, 128)     512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 64, 64, 256)       295168    \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 64, 64, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 64, 64, 256)       590080    \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 64, 64, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)       0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 262144)            0         \n","                                                                 \n"," dense (Dense)               (None, 150)               39321750  \n","                                                                 \n"," dropout (Dropout)           (None, 150)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               15100     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 100)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 27)                2727      \n","                                                                 \n","=================================================================\n","Total params: 40451385 (154.31 MB)\n","Trainable params: 40449721 (154.30 MB)\n","Non-trainable params: 1664 (6.50 KB)\n","_________________________________________________________________\n"]}],"source":["# 定義一個簡單的CNN模型\n","from tensorflow.keras import layers, models\n","model = models.Sequential([\n","    layers.Conv2D(64, (3, 3), padding=\"same\",activation='relu', input_shape=(256, 256, 3)),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(150, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(100, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(27, activation='softmax')\n","])\n","#from tensorflow.keras import layers, models\n","#model = models.Sequential([\n","#    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n","#    layers.Dropout(0.3),\n","#    layers.MaxPooling2D((2, 2)),\n","#    layers.Conv2D(64, (3, 3), activation='relu'),\n","#    layers.Dropout(0.3),\n","#    layers.MaxPooling2D((2, 2)),\n","#    layers.Conv2D(128, (3, 3), activation='relu'),\n","#    layers.Dropout(0.3),\n","#    layers.MaxPooling2D((2, 2)),\n","#    layers.Flatten(),\n","#    layers.Dense(128, activation='relu'),\n","#    layers.Dropout(0.3),\n","#    layers.Dense(150, activation='softmax')\n","#])\n","#from keras.models import load_model\n","#model = load_model('model.h5')\n","model.summary()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2650538,"status":"ok","timestamp":1716972605139,"user":{"displayName":"劉睿恩","userId":"00959352732132293814"},"user_tz":-480},"id":"Qe8YbupTTUfd","outputId":"2cc5a08b-b65f-4ddc-ae65-db38ef98a55d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 1s/step - accuracy: 0.0178 - loss: 5.0803 - val_accuracy: 0.0981 - val_loss: 4.0443\n","Epoch 2/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 1s/step - accuracy: 0.1238 - loss: 3.4857 - val_accuracy: 0.3067 - val_loss: 3.0912\n","Epoch 3/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 1s/step - accuracy: 0.3342 - loss: 2.3580 - val_accuracy: 0.3919 - val_loss: 2.5560\n","Epoch 4/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 1s/step - accuracy: 0.5144 - loss: 1.5932 - val_accuracy: 0.4633 - val_loss: 2.0848\n","Epoch 5/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 1s/step - accuracy: 0.6317 - loss: 1.1779 - val_accuracy: 0.5500 - val_loss: 1.7272\n","Epoch 6/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 1s/step - accuracy: 0.7122 - loss: 0.8885 - val_accuracy: 0.6230 - val_loss: 1.4849\n","Epoch 7/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 1s/step - accuracy: 0.7642 - loss: 0.7198 - val_accuracy: 0.5963 - val_loss: 1.4948\n","Epoch 8/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 1s/step - accuracy: 0.8119 - loss: 0.5700 - val_accuracy: 0.6874 - val_loss: 1.2101\n","Epoch 9/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 1s/step - accuracy: 0.8366 - loss: 0.5268 - val_accuracy: 0.5563 - val_loss: 1.5718\n","Epoch 10/10\n","\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 1s/step - accuracy: 0.8532 - loss: 0.4598 - val_accuracy: 0.6930 - val_loss: 1.1544\n"]}],"source":["## 編譯模型\n","#model.compile(optimizer='adam',\n","#       loss='categorical_crossentropy',\n","#       metrics=['accuracy'])\n","#\n","## 訓練模型\n","#history = model.fit(train_dataset, epochs=10, validation_data=valid_dataset)  #根據需要調整 epochs 數量"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":698,"status":"ok","timestamp":1716972605826,"user":{"displayName":"劉睿恩","userId":"00959352732132293814"},"user_tz":-480},"id":"PDj4NGeHPs5F","outputId":"2a643031-6cfd-4654-b55e-0f0a26890dcf"},"outputs":[{"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory)\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# set the vertical range to [0-1]\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"]}],"source":["## Learning curves\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","pd.DataFrame(history.history).plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n","plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71879,"status":"ok","timestamp":1716972677701,"user":{"displayName":"劉睿恩","userId":"00959352732132293814"},"user_tz":-480},"id":"0EY0u6DGPurl","outputId":"a68e9899-af4a-4220-e318-3454940b5ea0"},"outputs":[{"name":"stdout","output_type":"stream","text":["85/85 [==============================] - 26s 298ms/step - loss: 0.8556 - accuracy: 0.7807\n","340/340 [==============================] - 95s 278ms/step - loss: 0.8308 - accuracy: 0.7830\n","48/48 [==============================] - 12s 253ms/step - loss: 0.8372 - accuracy: 0.7854\n"]},{"data":{"text/plain":["[0.8371872305870056, 0.7854304909706116]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["## Model evaluation by test set\n","model.evaluate(valid_dataset)\n","model.evaluate(train_dataset)\n","model.evaluate(test_dataset)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
